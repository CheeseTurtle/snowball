
Usage: snowball [-h | -V]
       snowball [-v | -q] [-v | -o | -O] [-d] [-H]
                [-n number] [-f number]
                [-p number] [-k number]
                [-b number] [-e number | -E number]
                [-x chars] [-X number]
                [-i (delim) | -s file]
                [-c file (-C number)]
                [-r directory | -R directory]
                [l file | -L] [t file | -T]

Example: snowball -r directory-name
         snowball -s seed-phrases.txt
         echo "i am the,the only,the main,disqualified" | snowball -i,
         snowball -v -n100 -c a.txt -C3 -c b.txt -C2
         snowball -o -H -k2 -p100 -e8 > sbpoems-longkeys.txt

Program information:
  -h        Output help instructions
  -V        Output program information (version, author, contact info)

Console output:
  Default   Write snowball file names to stdout, errors to stderr
  -q        Do not write anything to standard or error output
  -o        Write the snowball poems to stdout instead of to separate files
  -O        Write the snowball poems to stdout immediately (don't sort them)
  -v        Write verbose program information to standard output
  -d        Debug. Write internal program vectors to separate files
  -H        Do not write verbose program information header to the file

Snowball generation:
                ( Arguments should be numeric integers )
  -n10000       Specify how many snowballs to attempt to create
  -f100000      Failed poems to ignore before just giving up
  -p70          Percentage chance to use longer word keys before shorter keys
  -k1           Specify a minimum word key size to use. Default is 1
  -b4           Begin poems at a word length other than 1
  -e8           Reject poems where last word is fewer than 'n' letters long
  -E8           Truncate poems so last word is exactly 'n' letters long
  -x [ chars ]  Create poems that exclude all argument letters
  -X3           Minimum word length to apply 'x' filtering to

Snowball seed phrases:
  -s filename.txt    Input seed phrases from a file, new line delimited
  -i [ delim ]       Input seed phrases from stdin, 'delim' delimited

Processing raw input:
  -c snowball-corpus.txt      The corpus file(s) containing snowballing words
  -C [ number ]               The weight of the corresponding corpus file
  -r ./input_directory        Create from raw English text files in directory
  -R ./root_directory         Same as -r, but loads files recursively
  -l snowball-lexicon.txt     The file that contains list of valid words
  -L                          Don't use a lexicon file to validate words
  -t snowball-thesaurus.txt   The file that contains the words to switch
  -T                          Don't use a thesaurus file to switch words